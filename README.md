# GenAI on AWS talk

Dear all, as the talk is based upon a lot of content, please find related links here:

* Convert text into vectors: Word2Vec online demo: https://remykarem.github.io/word2vec-demo/

* Classical example: King-Queen vs Man-Woman vectorization: https://www.researchgate.net/figure/The-classical-king-woman-man-queen-example-of-neural-word-embeddings-in-2D-It_fig1_332679657

* Try it yourself: "Semantic Calculator" based on vector values: http://vectors.nlpl.eu/explore/embeddings/en/calculator/#

* Amazon Commprehend (e.g. Sentiment Analysis) example (AWS Account needed): https://us-west-2.console.aws.amazon.com/comprehend/home?region=us-west-2#home

* Large Language Models - Youtube Video: https://www.youtube.com/watch?v=5sLYAQS9sWQ

* "Transformers, explained" Youtube Video: https://www.youtube.com/watch?v=SZorAJ4I-sA

* Semi-supervised learning: https://blog.roboflow.com/what-is-semi-supervised-learning/

* x

* Falcon 40B LLM: https://huggingface.co/tiiuae/falcon-40b-instruct

* Falcon LLMs creator: https://en.wikipedia.org/wiki/Technology_Innovation_Institute

* Billboard chart for LLMs: https://s10251.pcdn.co/wp-content/uploads/2023/06/2023-Alan-D-Thompson-AI-Billboard-Rev-1.png

* SageMaker Notebook: Text Generation with Falcon: https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart-foundation-models/text-generation-falcon.ipynb

* Should you Prompt, RAG or fine tune? https://medium.com/@pandey.vikesh/should-you-prompt-rag-tune-or-train-a-guide-to-choose-the-right-generative-ai-approach-5e264043bd7d

* 
